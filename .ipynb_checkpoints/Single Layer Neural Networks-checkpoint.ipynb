{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I need to import PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\"\n",
    "        Sigmoid activation function\n",
    "        \n",
    "        Arguments\n",
    "        -----------\n",
    "        x: torch.Tensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating some data\n",
    "torch.manual_seed(7) # Setting the random seed so things will be predictable\n",
    "# Features are 5 random variables\n",
    "features = torch.randn((1,5))\n",
    "# True weights for our data, random normal variables as well\n",
    "weights = torch.randn_like(features)\n",
    "# and a true bias term\n",
    "bias = torch.randn((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n"
     ]
    }
   ],
   "source": [
    "print (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]])\n"
     ]
    }
   ],
   "source": [
    "print (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3177]])\n"
     ]
    }
   ],
   "source": [
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1595]])\n"
     ]
    }
   ],
   "source": [
    "## Calculating the output of this network using the weights and bias tensors\n",
    "y = activation(torch.sum(features*weights)+bias)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1595]])\n"
     ]
    }
   ],
   "source": [
    "# We can also do the same using Matrix Multiplications; more efficient\n",
    "# torch.mm() or torch.matmul()\n",
    "##### Use tensor.shape to see the shape of a tensor: Mui importante for NNs #####\n",
    "# 3 different options for reshaping the tensor\n",
    "# tensor.reshape(a,b) will ret new tensor with same data with size (a,b)\n",
    "# tensor.resize_(a,b) ret same tensor with a different shape; this is in place\n",
    "# tensor.view(a,b) most used and ret new tensor with same data with size (a,b)\n",
    "# e.g if my tensor is 1 x 5 I can use tensor_name.view(5, 1) to have it be 5 x 1\n",
    "y_with_matrix_mul = activation(torch.mm(features, weights.view(5, 1)) + bias)\n",
    "print(y_with_matrix_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1468,  0.7861,  0.9468]])\n",
      "3\n",
      "tensor([[0.3171]])\n"
     ]
    }
   ],
   "source": [
    "# Generating some data\n",
    "torch.manual_seed(7)       # random seed for predicatbility\n",
    "\n",
    "# Features are 3 random normal variables\n",
    "features_nn = torch.randn((1, 3))\n",
    "print(features_nn)\n",
    "print(features_nn.shape[1])\n",
    "# Define the size of each layer in our network\n",
    "n_input = features_nn.shape[1]      # Number of input units, must match number of input features\n",
    "n_hidden = 2                     # Number of hidden units\n",
    "n_output = 1                     # Number of output units\n",
    "\n",
    "# Weights for inputs to hidden layer\n",
    "weights_1 = torch.randn(n_input, n_hidden)      # (3,2)\n",
    "weights_2 = torch.randn(n_hidden, n_output)     # (2,1)\n",
    "\n",
    "# and the bias terms for hidden and output layers\n",
    "bias_1 = torch.randn((1, n_hidden))\n",
    "bias_2 = torch.randn((1, n_output))\n",
    "\n",
    "input_to_hidden = activation(torch.mm(features_nn, weights_1) + bias_1)\n",
    "hidden_to_output = activation(torch.mm(input_to_hidden, weights_2) + bias_2)\n",
    "print(hidden_to_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
