{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "# Download and load the training data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 784])\n",
      "Logits shape:  torch.Size([64, 10])\n",
      "Labels shape:  torch.Size([64])\n",
      "tensor(2.3235, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Building a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "# dim = 1 so it calc across the columns\n",
    "\n",
    "# Defining the loss\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get the data\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "# Need to flatten the images\n",
    "images = images.view(images.shape[0], -1)\n",
    "print(images.shape)\n",
    "\n",
    "# Forward pass to get logits; these are the scores from the output model\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(\"Logits shape: \", logits.shape)\n",
    "print(\"Labels shape: \", labels.shape)\n",
    "\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1224, -0.4068],\n",
      "        [ 0.4786,  0.9832]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Autograd does the backpropagation for us\n",
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2599, 0.1655],\n",
      "        [0.2290, 0.9667]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x0000020A5E8FC2E8>\n"
     ]
    }
   ],
   "source": [
    "# grad_fn shows us the fn that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6553, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# reducing the tensor y to a scalar value we can get the mean\n",
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5612, -0.2034],\n",
      "        [ 0.2393,  0.4916]])\n",
      "tensor([[ 0.5612, -0.2034],\n",
      "        [ 0.2393,  0.4916]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print (x.grad)\n",
    "print (x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 0.0010,  0.0010,  0.0010,  ...,  0.0010,  0.0010,  0.0010],\n",
      "        [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
      "        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
      "        ...,\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009]])\n"
     ]
    }
   ],
   "source": [
    "print ('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print ('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0355, -0.0271, -0.0145,  ...,  0.0164,  0.0225,  0.0055],\n",
      "        [-0.0087, -0.0126, -0.0154,  ..., -0.0077,  0.0106, -0.0311],\n",
      "        [-0.0076, -0.0033,  0.0088,  ...,  0.0151,  0.0280,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0260, -0.0325,  0.0052,  ..., -0.0205,  0.0089, -0.0218],\n",
      "        [ 0.0349, -0.0322, -0.0328,  ..., -0.0240, -0.0113,  0.0248],\n",
      "        [-0.0241,  0.0149,  0.0287,  ..., -0.0142, -0.0341,  0.0330]],\n",
      "       requires_grad=True)\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "Gradient - tensor([[-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
      "        [-0.0025, -0.0025, -0.0025,  ..., -0.0025, -0.0025, -0.0025],\n",
      "        [-0.0030, -0.0030, -0.0030,  ..., -0.0030, -0.0030, -0.0030],\n",
      "        ...,\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [-0.0001, -0.0001, -0.0001,  ..., -0.0001, -0.0001, -0.0001],\n",
      "        [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]])\n",
      "Updated weights - Parameter containing:\n",
      "tensor([[ 0.0355, -0.0271, -0.0145,  ...,  0.0164,  0.0225,  0.0055],\n",
      "        [-0.0087, -0.0126, -0.0154,  ..., -0.0076,  0.0106, -0.0311],\n",
      "        [-0.0076, -0.0033,  0.0088,  ...,  0.0151,  0.0281,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0260, -0.0325,  0.0052,  ..., -0.0205,  0.0089, -0.0218],\n",
      "        [ 0.0349, -0.0322, -0.0328,  ..., -0.0240, -0.0113,  0.0248],\n",
      "        [-0.0241,  0.0149,  0.0287,  ..., -0.0142, -0.0341,  0.0330]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# One training step in PyTorch has 4 diff steps\n",
    "\n",
    "# [1] First we make a forward pass thru the network\n",
    "\n",
    "# [2] Use the network output to calc loss\n",
    "\n",
    "# [3] Perform backward pass using loss.backward\n",
    "\n",
    "# [4] Make a step with optimizer to update the weights\n",
    "\n",
    "print ('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.shape)\n",
    "images.resize_(64, 784)\n",
    "print(images.shape)\n",
    "\n",
    "# Clear gradients since PT accumulates grads\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass then update weights\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print ('Gradient -', model[0].weight.grad)\n",
    "\n",
    "# The update step\n",
    "optimizer.step()\n",
    "print('Updated weights -', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.216281074196545\n",
      "Training loss: 1.901894050747601\n",
      "Training loss: 1.396335139584694\n",
      "Training loss: 0.9812328819908313\n",
      "Training loss: 0.7553746165243039\n"
     ]
    }
   ],
   "source": [
    "######### Trying out a training of the dataset\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 784])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can now see the predictions of the network\n",
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "print(images[0].shape)\n",
    "img = images[0].view(1, 784)\n",
    "print(img.shape)\n",
    "\n",
    "# Turning off gradients to speed up\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "    \n",
    "# output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(logits, dim=1)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
