{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages for ease of use\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the MNIST dataset in the identification of text in an image\n",
    "# MNIST consists of greyscale handwritten digits; each image is 28x28 pixels\n",
    "# The goal is to build an NN to take any image and predict the digit in the image\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# we can use the trainloader object in a for loop ::: for image, label in trainloader:\n",
    "#                                                         do things with images and labels\n",
    "# batch size is the number of images we get in one iteration from the data loader\n",
    "# shuffle tells it to shuffle the dataset every time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x257c20ac908>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can see how an image looks like\n",
    "plt.imshow(images[63].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 10])\n",
      "tensor([[ -9.9304,  -8.9026,  -7.8685,  -8.0275,  14.5250, -10.3544,   2.8135,\n",
      "           3.8199,   2.4485,  29.7391],\n",
      "        [ -1.8869,  -8.3896, -10.6447,  -6.1789,  15.0291,  -7.1249,  -5.3183,\n",
      "           4.6844,  17.9743,  39.3664],\n",
      "        [-12.2305,   2.7640, -13.8526,  -2.3625,   9.4439, -11.5218,  -6.0000,\n",
      "           7.6535,  -1.9586,  33.6608],\n",
      "        [ -4.0201,   9.6818, -14.8365,  -6.0659,  11.1650,  -1.8317,  -5.1201,\n",
      "           3.3262,   2.9449,  17.3303],\n",
      "        [ -7.7954,   4.4435,  -8.9281,  -0.6301,   6.7177,  -5.3472,   7.5762,\n",
      "           0.6441,  13.0231,  34.0304],\n",
      "        [ -2.7910,   8.1767,  -6.5630,  -8.8419,  14.6394,  -5.2926,  -2.1668,\n",
      "           6.5178,   3.9193,  30.3003],\n",
      "        [ -8.3011,  -4.6067, -14.4057,  -9.6481,  12.4834,  -3.8495,  -1.0988,\n",
      "           3.9186,   2.7033,  23.5413],\n",
      "        [ -7.3268,   2.1940, -13.7532,   1.8120,   5.6704,  -9.2766,  -2.3345,\n",
      "           6.2758,  21.4571,  30.2368],\n",
      "        [ -5.7950,  -0.3789, -13.0661,  -7.2700,  11.2342,   7.8786,   1.9478,\n",
      "           4.9081,  11.0454,  26.4568],\n",
      "        [ -5.6322, -11.5912, -24.0362,   3.7923,   2.8789,   0.0528,  -0.3792,\n",
      "           5.7504,  15.0460,  24.7252],\n",
      "        [ -0.1803,   0.0542,  -6.5712, -11.7637,   4.8644,  -8.4014,   2.0660,\n",
      "          11.3008,   2.3351,  23.8992],\n",
      "        [ -3.5386,   7.6641,  -6.1805,  -8.5000,  18.3851,  -8.0899,   5.0778,\n",
      "          15.4364,   0.3127,  28.8526],\n",
      "        [ -3.1294,  12.0014,  -4.9336,  -8.5442,  13.0841,   6.5593,   9.2341,\n",
      "          10.4266,  10.8951,  16.2421],\n",
      "        [ -2.6571,  -1.4034, -15.7894,  -7.3254,   8.1907,  -0.0717,  -3.7818,\n",
      "          11.0211,   6.2687,  31.5038],\n",
      "        [-11.2671,   7.2747, -12.3416,  -1.2346,  -1.3447,   4.8834,  -3.7524,\n",
      "           5.2189,   6.4341,  21.1007],\n",
      "        [ -6.9582,   5.1399, -10.9833, -13.5083,   5.8295,   2.2408,   0.2250,\n",
      "           8.3168,   6.7092,  31.5674],\n",
      "        [ -3.5380,   6.8533, -13.6722,  -6.2165,   9.9490,  -6.7369,   9.3195,\n",
      "           7.4696,   1.6676,  27.0789],\n",
      "        [  5.4149,   4.5525, -12.9628,  -2.1271,  10.8809,  -4.2293,  13.3420,\n",
      "          19.0458,  11.5735,  39.9330],\n",
      "        [-11.1614,  10.5482,  -9.4393, -17.6410,   2.9549,  -2.9834,   3.6882,\n",
      "          10.2334,   7.0711,  22.1864],\n",
      "        [ -4.9875,  -3.1170,   0.7818, -12.1085,  19.4114,  -2.1497,   9.4853,\n",
      "           8.6733,  -0.0567,  33.3297],\n",
      "        [ -7.6794,   4.7998,  -8.8557, -11.3070,   8.4311,   1.7175,  -0.2820,\n",
      "          12.3213,   6.2695,  28.4006],\n",
      "        [ -4.7345,   7.4999,  -6.2916, -11.7452,  14.0673,  -5.4994,  -3.1761,\n",
      "           3.6530,   1.0795,  29.9236],\n",
      "        [ -0.5595,  -7.3650, -12.4855, -14.2725,  10.3944,  -3.2354,  13.4493,\n",
      "           6.7598,   5.5166,  26.2232],\n",
      "        [ -9.0806,  10.5710, -13.0620, -10.6949,   7.1526,   5.1638,   4.1202,\n",
      "           4.7387,   7.4931,  26.7772],\n",
      "        [-16.4782,   5.2727,  -6.9008, -13.7415,  10.0167,  -1.5424, -10.7419,\n",
      "          15.3952,   3.9230,  28.9325],\n",
      "        [ -3.8847,   6.7142, -11.8236,  -6.4508,  -3.4507,  -0.9388,  11.7696,\n",
      "           3.2896,   1.3557,  29.9804],\n",
      "        [ -5.3190,  -8.6084,  -0.2462, -11.2150,  11.8822,  -5.5900,  -0.4941,\n",
      "           6.0669,   0.5247,  33.1944],\n",
      "        [ -5.7830,   9.1742, -16.7821, -15.4441,  11.6991,   0.4789,  -4.2072,\n",
      "           1.9752,   8.9085,  23.1853],\n",
      "        [-11.9345,  -2.9245, -23.2455, -10.5933,   5.3915,   5.5326,   2.5795,\n",
      "           8.9700,   5.9019,  25.1765],\n",
      "        [ -1.5590,   9.6327,  -6.9505,  -5.1711,  10.0007,  -1.0182,  -7.5975,\n",
      "           8.4876,   7.0904,  27.5230],\n",
      "        [ -3.3351,  16.6775,  -8.2180, -10.3031,  12.4789, -11.7644,   3.9041,\n",
      "           7.4728,  -6.2354,  28.1461],\n",
      "        [ -3.2314,   7.9160, -14.3954,  -6.5924,  11.9040,  -1.8396,   3.1265,\n",
      "          15.2596,   3.0232,  33.4980],\n",
      "        [-16.6976,  14.5159,  -8.1632,  -5.6658,  11.8165,  -3.9995,  -0.4420,\n",
      "           6.9449,   2.4199,  32.4357],\n",
      "        [ -1.0199,   1.8678,  -9.2739,  -9.1568,  16.9457,   0.2764,  11.2331,\n",
      "           8.1902,   2.0411,  20.1637],\n",
      "        [-16.9072,  -5.1692,  -9.5240,  -4.0563,  12.9266,  -2.7214,  -4.2279,\n",
      "          12.1315,   6.1845,  36.8429],\n",
      "        [ -9.2920,  -4.3929, -12.5051, -12.5529,  12.6687,  -3.5525,   2.7889,\n",
      "           3.5793,   4.7369,  24.1483],\n",
      "        [ -8.5520,   2.6572,  -4.8525, -13.3045,   3.8744, -13.1092,   7.8449,\n",
      "          10.1191,   1.1072,  29.8439],\n",
      "        [ -2.3745,   2.5446,  -5.1388,  -3.9181,  13.4519,  -0.7664,   4.0337,\n",
      "          10.9924,   7.4357,  30.7662],\n",
      "        [  0.5742,   4.2068,  -9.4467, -10.2567,   8.3092,   4.8619,   2.3657,\n",
      "           0.3376,  14.3869,  18.2680],\n",
      "        [ -4.4613,   8.0693, -10.0109,  -3.0698,   5.2345,  -1.2820,   6.1904,\n",
      "           8.8838,   0.9308,  35.3924],\n",
      "        [ -4.7473,  -1.4327, -12.8420,  -8.4841,  16.5666,  -8.6067,   8.1145,\n",
      "          19.1277,  11.7753,  34.6984],\n",
      "        [ -4.6930,  -1.8818, -12.8109, -15.5308,  22.8446,  -9.7535,  -1.3907,\n",
      "           3.0966,  -2.8837,  18.5813],\n",
      "        [ -4.9370,   4.1177, -13.3356,  -8.4569,  10.3361,  -5.1012,   6.8946,\n",
      "          12.7533,   1.1646,  32.5638],\n",
      "        [ -9.1729,   3.0820, -14.5456, -14.6135,  15.0735,  -1.1878,   0.9134,\n",
      "           5.1142,   3.0735,  21.7159],\n",
      "        [ -1.2324,   3.3988, -11.7866, -15.8566,   6.3351,  -2.3267,   8.8426,\n",
      "           5.5843,   3.6539,  24.6091],\n",
      "        [ -1.2112,   5.3099,  -8.4680,  -2.7465,   8.7147,   0.4044,   5.6803,\n",
      "           4.8916,   4.0584,  24.3727],\n",
      "        [ -2.0810,   4.1665,  -8.6393, -11.3263,  11.8698,   4.1770,   7.6403,\n",
      "          -0.7050,   4.8587,  18.9410],\n",
      "        [ -8.2827,  -1.3590,  -9.4216,  -7.8463,   8.8432,   1.3192,   3.0330,\n",
      "           1.1552,   9.8799,  32.0390],\n",
      "        [  0.4815,   3.1762, -10.9552, -11.9560,   9.1942,  -3.0110,   3.2730,\n",
      "          10.3153,   4.6077,  27.6241],\n",
      "        [ -7.0116,   4.2968,  -3.3890,  -6.4055,  19.1833,  -7.1002,  13.8294,\n",
      "           7.0118,   9.6871,  26.2969],\n",
      "        [ -7.3117,  -6.0921, -11.5455,  -6.1836,   8.1406,  -7.8372,   3.0386,\n",
      "          14.5935,  -0.5161,  20.9181],\n",
      "        [-13.5024, -13.0667, -13.9746,  -9.8058,  13.6153,  -8.1363,  10.7689,\n",
      "          10.2567,   5.0116,  34.0573],\n",
      "        [-14.0112,   8.8900, -10.3081, -18.2976,   8.0362,  -8.6273,   7.0565,\n",
      "          11.8399,  -0.5572,  35.3230],\n",
      "        [ -0.6087,   6.1939,  -5.8384, -11.0190,  -0.0686,  -9.0585,   4.4718,\n",
      "          10.7565,   1.7370,  20.8690],\n",
      "        [ -8.0431,  -5.3117, -21.2898,  -9.3461,  22.9085,  -0.9742,  -1.3228,\n",
      "           2.0620,  -4.1502,  22.8098],\n",
      "        [ -4.2224,  -5.3608, -18.5053,  -7.1600,  13.6815,   0.3351,  -0.4758,\n",
      "           6.5304,   7.2690,  27.6601],\n",
      "        [ -3.8592,   4.6583, -18.1266, -10.3957,   9.9485,  -7.0173,   9.6987,\n",
      "           6.7885,   8.8614,  27.0176],\n",
      "        [ -1.9623,   2.4005,  -3.5695,   1.0043,  19.0524,  -3.4841,   7.6758,\n",
      "          13.3416,   8.1509,  33.8403],\n",
      "        [ -7.1209,  -5.1467, -10.5187,  -7.6005,  12.1238,  -6.7021,   0.4112,\n",
      "           8.8646,  10.4030,  28.3994],\n",
      "        [ -1.3099,   5.9825,  -9.6358, -10.1154,   7.9746,  -4.8106,   3.6352,\n",
      "           5.7290,   5.8271,  30.2431],\n",
      "        [ -6.5033,   7.8929, -12.1892, -13.7216,  13.8181,  -0.4273,   1.2173,\n",
      "          14.7829,   2.4210,  35.2613],\n",
      "        [-10.4590,   7.8781, -10.4409, -14.5300,  17.5184, -11.0733,   4.7364,\n",
      "           4.1960,   2.8146,  25.7817],\n",
      "        [ -2.6190,   3.5411,  -8.3581,  -5.9220,   3.6525,  -5.7618,  -4.4418,\n",
      "           6.4413,   0.4044,  26.1231],\n",
      "        [-12.7048,   1.9992, -16.7368, -10.7368,   7.1275,  -4.8275,   3.9976,\n",
      "           0.8585,  -4.0576,  32.2535]])\n"
     ]
    }
   ],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "# Flattening the input images\n",
    "print(images.shape[0])\n",
    "# images.shape[0] gives us the batch size i.e 64 since images.shape => (64, 1, 28, 28)\n",
    "# the -1 automatically calculates from the remaining 3 and gives us 784\n",
    "inputs = images.view(images.shape[0], -1)\n",
    "print(inputs.shape)\n",
    "\n",
    "# Create parameters\n",
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, w1)+b1)\n",
    "\n",
    "out = torch.mm(h, w2) + b2\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# We now need the prob from the above that it belongs to one of the certain classes\n",
    "# To do so, we use Softmax function\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1,1)\n",
    "\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Checking it has the right shape of (64,10)\n",
    "print(probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Building Networks easily with the PyTorch nn module\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        # Pytorch uses this to recognize what the network has\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer that has 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define the sigmoid activation and softmax function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetworkF(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "class NetworkF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation; typically ReLu is what is used today due to speed and efficiency\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax function\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "modelF = NetworkF()\n",
    "modelF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
